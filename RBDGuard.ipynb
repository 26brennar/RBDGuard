{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3989c93-a1df-4ffb-b8f1-8b05cd340468",
   "metadata": {},
   "source": [
    "NOTE: Used for running the RBDGuard framework on preprocessed data (see preprocessing.ipynb). Runs both the unsupervised and supervised training.\n",
    "\n",
    "** I ran this on a Google Colab, so the file paths are slightly different since I uploaded the pickle files to a virtual machine **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d6cd8-6fe6-42e6-835c-7aaefd6ffe7b",
   "metadata": {},
   "source": [
    "Retrieve imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767ba35-60ff-4e6a-bb5a-6ef2914a249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pyedflib import highlevel\n",
    "import pyedflib as plib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.models import load_model\n",
    "import neurokit2 as nk\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6fe99-81b0-4e1a-8922-c1b552543570",
   "metadata": {},
   "source": [
    "Read back the unlabeled data stored in pickle files on desktop and store as DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4a514-da8b-4490-8989-121b6172afab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to read back\n",
    "unlabeled_cfs = pd.read_pickle(\"/content/CFS_cleaned_ECG_data_30s_all.pkl.gz\")\n",
    "unlabeled_shhs1 = pd.read_pickle(\"/content/shhs1_cleaned_ECG_data_30s_all.pkl.gz\")\n",
    "unlabeled_shhs2 = pd.read_pickle(\"/content/shhs2_cleaned_ECG_data_30s_all.pkl.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96257f3f-69cc-491c-bc3d-11aaf1718784",
   "metadata": {},
   "source": [
    "Concatenates the CFS, SHHS1, and SHHS2 DataFrame into one large unlabeled data DataFrame. Creates the training values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c789ef-d2fc-4e8a-87bd-31b112d32af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df = pd.concat([unlabeled_cfs, unlabeled_shhs1, unlabeled_shhs2])\n",
    "\n",
    "unlabeled_x_train = unlabeled_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362473a-4013-4d28-90e5-5da0cb13a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X so that it can pass through LSTM layer\n",
    "unlabeled_x_train = unlabeled_x_train.reshape(unlabeled_x_train.shape[0], unlabeled_x_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b84d35-4141-4f2d-a7da-5a7e04afcc49",
   "metadata": {},
   "source": [
    "Declares the model architecture for the unsupervised portion (bidirectional LSTM model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a1a87-d64d-4407-9f17-5aae0ea5b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoderDecoder(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(LSTMEncoderDecoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input((240, 1)),  # Define input shape here\n",
    "            layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.2), name='Bi-LSTM1'), ## Change for different input sizes\n",
    "            layers.Bidirectional(layers.LSTM(32, dropout=0.2), name='Bi-LSTM2')])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            #layers.Input(shape=(32 * 2,)),  # Adjust based on encoder output\n",
    "            layers.RepeatVector(240), # Change for different inputs\n",
    "            layers.Bidirectional(layers.LSTM(32, return_sequences=True, dropout=0.2), name='Bi-LSTM3'),\n",
    "            layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.2), name='Bi-LSTM4'),\n",
    "            layers.TimeDistributed(layers.Dense(1))])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab7495-3d4e-4212-853a-9d902548ccc7",
   "metadata": {},
   "source": [
    "Declares function to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33926c-d749-4d30-b660-1890539a40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, loss=True, validation=False):\n",
    "    if loss:\n",
    "        plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "        if validation:\n",
    "            plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "        if validation:\n",
    "            plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df5347f-3839-468b-8188-dd7b020f327b",
   "metadata": {},
   "source": [
    "Runs the unsupervised model portion. Uses an optimizer to improve efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c2d83-77dc-4633-a835-a369c4ada3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = LSTMEncoderDecoder()\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7542e3-44fe-4e93-ab7c-b3555a0b0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72952c55-9df5-412c-b7e1-1bd665b3c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(unlabeled_x_train, unlabeled_x_train, epochs=50, batch_size=256, verbose=1)\n",
    "plot_history(history, loss=True, validation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45614f5-317e-4180-9fcd-0b49785f4eac",
   "metadata": {},
   "source": [
    "(OPTIONAL) Save the autoencoder model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef69942-5736-4ebc-b7b5-daefa54d3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('unsupervised_lstm_50epochs_cfs_shhs1_shhs2_202501041412.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14415fd6-3711-492d-a19a-75c3e839bc8d",
   "metadata": {},
   "source": [
    "(OPTIONAL) Prints model summary of encoder and decoder -- table with layer type, output shape, and parameter count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25b906-8850-48d2-931b-acd1d509b046",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dabb678-a6ca-4680-863e-d85a2f967a06",
   "metadata": {},
   "source": [
    "Run to declare unsupervised + supervised model (RBDGuard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5ff39-5d13-498b-91fc-7e720c1eed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN EVERY TIME\n",
    "x = autoencoder.encoder.layers[-1].output\n",
    "x = layers.Dense(128, activation='relu')(x)  # Example hidden layer\n",
    "x = layers.Dropout(0.25)(x)  # Dropout with 25% rate\n",
    "x = layers.Dense(64, activation='relu')(x)  # Another hidden layer\n",
    "x = layers.Dropout(0.25)(x)  # Dropout with 25% rate\n",
    "x = layers.Dense(1, activation='sigmoid')(x)  # Output layer for binary classification (sigmoid)\n",
    "predictive_model = keras.Model(autoencoder.encoder.layers[0].input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234c9d6-d999-476b-8dd3-f833be9aaef3",
   "metadata": {},
   "source": [
    "Run to declare only supervised model. Note: Only run this cell if testing only-supervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcec0f-4f32-45c2-a560-995f887df4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model input layer\n",
    "# input_layer = keras.Input(shape=((240,1)))  # Replace input_shape with your input size\n",
    "\n",
    "# Add layers as per your model's architecture\n",
    "# x = layers.Flatten()(input_layer)\n",
    "# x = layers.Dense(128, activation='relu')(x)  # Example hidden layer\n",
    "# x = Dropout(0.5)(x)  # Dropout with 50% rate\n",
    "# x = layers.Dense(64, activation='relu')(x)  # Another hidden layer\n",
    "# x = Dropout(0.3)(x)  # Dropout with 30% rate\n",
    "# x = layers.Dense(1, activation='sigmoid')(x)  # Output layer for binary classification (sigmoid)\n",
    "\n",
    "# # Create the model\n",
    "# predictive_model = keras.Model(inputs=input_layer, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a501d-1fa7-467c-a208-05996dd79f22",
   "metadata": {},
   "source": [
    "(OPTIONAL) Prints model summary of supervised model portion -- table with layer type, output shape, and parameter count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b521e63-0cf8-4322-9133-841aaa08e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de15cca2-8c86-49b8-9c30-25041e4aa033",
   "metadata": {},
   "source": [
    "Divides the labeled data for training, validation, and testing (85/15/15 split). Randomly shuffles the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15216e27-8963-43ac-acb6-4c037c765901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Read labeled data\n",
    "labeled_df = pd.read_pickle(\"/content/capslpdb_cleaned_ECG_data_30s_all.pk1.gz\")\n",
    "\n",
    "# First split: 15% for the test set and 85% for the train/validation split\n",
    "labeled_train_val_df, labeled_test_df = train_test_split(labeled_df, test_size=0.15)\n",
    "\n",
    "# Second split: 15% of the original data (from the 85%) for validation\n",
    "validation_ratio = 0.15 / 0.85  # Adjust to get 15% of the original dataset for validation\n",
    "labeled_train_df, labeled_val_df = train_test_split(labeled_train_val_df, test_size=validation_ratio)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"Training set size:\", len(labeled_train_df))\n",
    "print(\"Validation set size:\", len(labeled_val_df))\n",
    "print(\"Test set size:\", len(labeled_test_df))\n",
    "print(labeled_train_df.head(10))\n",
    "print(labeled_val_df.head(10))\n",
    "print(labeled_test_df.head(10))\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "labeled_x_train = labeled_train_df.drop(columns=0).values\n",
    "labeled_y_train = labeled_train_df[0].values\n",
    "\n",
    "labeled_x_val = labeled_val_df.drop(columns=0).values\n",
    "labeled_y_val = labeled_val_df[0].values\n",
    "\n",
    "labeled_x_test = labeled_test_df.drop(columns=0).values\n",
    "labeled_y_test = labeled_test_df[0].values\n",
    "\n",
    "# Encode labels\n",
    "encode_label = LabelEncoder()\n",
    "encode_label.fit(labeled_y_train)\n",
    "\n",
    "y_train = encode_label.transform(labeled_y_train)\n",
    "y_val = encode_label.transform(labeled_y_val)\n",
    "y_test = encode_label.transform(labeled_y_test)\n",
    "\n",
    "# Print to confirm encoding\n",
    "print(\"Classes:\", encode_label.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02adf61-a21f-4572-a8ae-3183d744deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X so that it can pass through LSTM layer\n",
    "labeled_x_train = labeled_x_train.reshape(labeled_x_train.shape[0], unlabeled_x_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc3ac07-c14f-4f67-ac68-63453e8fa56f",
   "metadata": {},
   "source": [
    "Run supervised model portion. Accounts for class imbalance and implements early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2be09-acf1-4e7b-9f5b-5aafecc0a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_weight = len(y_train) / np.sum(y_train == 0)\n",
    "class_1_weight = len(y_train) / np.sum(y_train == 1)\n",
    "\n",
    "class_weights = {0: class_0_weight, 1: class_1_weight}\n",
    "print(class_weights)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "predictive_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "model_history = predictive_model.fit(\n",
    "    labeled_x_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(labeled_x_val, y_val),  # Include validation data here\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "plot_history(model_history, loss=True, validation=True)\n",
    "plot_history(model_history, loss=False, validation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207393f-a3bd-4f7a-b57e-cece6db42298",
   "metadata": {},
   "source": [
    "(OPTIONAL) Save the RBDGuard model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93938791-9a96-4917-a9f0-84ea662f408b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictive_model.save('supervised_lstm_100epochs_70_15_15split_cfs_shhs1_shhs2_all_balanced.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f1fd4-ea20-4f22-a058-ee4a49fe16e9",
   "metadata": {},
   "source": [
    "Tests RBDGuard using the testing data (prints accuracy, F1 score, precision, recall, and confusion matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea551296-990b-4bac-b2b9-9233246fd75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = predictive_model.predict(labeled_x_test)\n",
    "pred_test = np.where(pred_test > 0.5, 1,0).reshape(-1,)\n",
    "print (pred_test)\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, pred_test)*100}%')\n",
    "print(f'Test F1 Score: {f1_score(y_test, pred_test, average=\"micro\")*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84434b1e-108f-4e8e-9fec-be913f6b1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"RBD\", \"Normal\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda0998a-fd29-463e-83e9-8af9cff16dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test, target_names=[\"RBD\", \"Normal\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
