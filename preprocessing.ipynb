{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1328f3-2d67-4327-ac81-4dd1e6268b73",
   "metadata": {},
   "source": [
    "NOTE: Used to preprocess ECG samples. Takes downloaded EDF files on desktop and converts to usable ECG segments stored in Pickle files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d6cd8-6fe6-42e6-835c-7aaefd6ffe7b",
   "metadata": {},
   "source": [
    "Retrieve imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767ba35-60ff-4e6a-bb5a-6ef2914a249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pyedflib import highlevel\n",
    "import pyedflib as plib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.models import load_model\n",
    "import neurokit2 as nk\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd81df5-3cb6-464d-9689-8dc83048c2bc",
   "metadata": {},
   "source": [
    "(Optional) Read metadata of the file (what the ECG channel is named as, sampling frequency, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb8f9f-0c8f-40c7-865f-3ffc752ca33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"INSERT FILE PATH\"\n",
    "signals, signal_headers, header = highlevel.read_edf(file_path, ch_names=\"ECG\")\n",
    "print(signal_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a0cdf7-431c-4f26-86be-4e9c00767b77",
   "metadata": {},
   "source": [
    "Preprocessing unlabeled data. Read directly from files stored on desktop (previously downloaded as EDFs). Apply Neurokit2 cleaning filter and save all the data in a DataFrame. Then save the dataframe as a pickle file (space-efficient).\n",
    "\n",
    "Must run once for each database (change the root directory path and pickle file path as needed).\n",
    "\n",
    "Notes: Only takes 42 samples per ECG from t=10000s to t=20000s. If the ECG channel name is not name \"ECG\", then the read_edf parameter must be modified as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4e484-8727-422d-9420-6c300c061ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_directory_path = \"F:\\\\Research\\\\wsc\\\\polysomnography\"\n",
    "\n",
    "pickle_file_path = \"C:\\\\Users\\\\Gang Ren\\\\Research\\\\wsc_cleaned_ECG_data_30s_all.pkl.gz\"\n",
    "\n",
    "master_df = pd.DataFrame({})\n",
    "\n",
    "# Iterate over files in directory\n",
    "file_count = 0\n",
    "sample_count = 0\n",
    "for name in os.listdir(root_directory_path):\n",
    "    try:\n",
    "        # Open file\n",
    "        file_path = os.path.join(root_directory_path, name);\n",
    "        signals, signal_headers, header = highlevel.read_edf(file_path, ch_names=\"ECG\")\n",
    "        \n",
    "        # Calculate the factor by which to downsample\n",
    "        factor = (int) (signal_headers[0]['sample_frequency'] // 8.0) ## Frequency = 8.0 hz\n",
    "    \n",
    "        size = signals[0].size\n",
    "        \n",
    "        # Ensure the size is divisible by the factor\n",
    "        truncated_size = size - (size % factor)\n",
    "        downsampled = signals[0][:truncated_size].reshape(-1, factor).mean(axis=1)\n",
    "\n",
    "    \n",
    "        for i in range(10000, 20000, 240):\n",
    "            downsampled_slice = downsampled[i:i+240] ## 240 samples, 30 s\n",
    "            cleaned = nk.ecg_clean(downsampled_slice, sampling_rate=8.0, method=\"neurokit\") ## Frequency = 8.0 hz\n",
    "            df = pd.DataFrame({name : cleaned}).T\n",
    "            master_df = pd.concat([master_df, df]);\n",
    "            sample_count += 1\n",
    "        file_count += 1\n",
    "    \n",
    "        print (\"Done with file \" + str(file_count) + \", Done with \" + str(sample_count) + \" samples, Original Sampling Rate \" + str(signal_headers[0]['sample_frequency']))\n",
    "    \n",
    "        master_df.to_pickle(pickle_file_path, compression=\"gzip\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Catch and log any errors for the current file\n",
    "        print(f\"Error processing file {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e49ff-e4b0-4e9c-a705-0aa9a12fc218",
   "metadata": {},
   "source": [
    "Preprocessing labeled data (CAP database). Read directly from files stored on desktop (previously downloaded as EDFs). Apply Neurokit2 cleaning filter and save all the data in a DataFrame. Then save the dataframe as a pickle file (space-efficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a25189-c109-43b9-8901-fe06a1d86924",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory_path = \"F:\\\\Research\\\\capslpdb\"\n",
    "\n",
    "# File path for the pickle file\n",
    "pickle_file_path = \"C:\\\\Users\\\\Gang Ren\\\\Research\\\\capslpdb_cleaned_ECG_data_30s_all.pk1.gz\"\n",
    "\n",
    "master_df = pd.DataFrame({})\n",
    "\n",
    "n_count = 0\n",
    "rbd_count = 0\n",
    "\n",
    "# Iterate over files in directory\n",
    "for name in os.listdir(root_directory_path):\n",
    "    if name.endswith(\".edf\") == False:\n",
    "        continue\n",
    "    \n",
    "    if name.startswith(\"rbd\"):\n",
    "        label = -1\n",
    "    elif name.startswith(\"n\") and name.startswith(\"nfle\") == False and name.startswith(\"narco\") == False:\n",
    "        label = 1\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Open file -- account for the different channel names in CAP database\n",
    "    file_path = os.path.join(root_directory_path, name);\n",
    "    try:\n",
    "        signals, signal_headers, header = highlevel.read_edf(file_path, ch_names=\"ECG1-ECG2\")\n",
    "        if (len(signals) == 0):\n",
    "            signals, signal_headers, header = highlevel.read_edf(file_path, ch_names=\"ECG\")\n",
    "        if (len(signals) == 0):\n",
    "            signals, signal_headers, header = highlevel.read_edf(file_path, ch_names=\"EKG\")\n",
    "    except OSError as err:\n",
    "        print(\"OS error: \" + file_path)\n",
    "\n",
    "    # Calculate the factor by which to downsample\n",
    "    try:\n",
    "        factor = (int) (signal_headers[0]['sample_frequency'] // 8.0)\n",
    "    except IndexError as err:\n",
    "        print (\"Index error: \" + file_path)\n",
    "    else:\n",
    "        downsampled = signals[0].reshape(-1, factor).mean(axis=1)\n",
    "        print(len(downsampled))\n",
    "        for i in range(0, len(downsampled)-240, 240):\n",
    "            downsampled_slice = downsampled[i:i+240] ## 240 samples, 30 s\n",
    "            cleaned = nk.ecg_clean(downsampled_slice, sampling_rate=8.0, method=\"neurokit\")\n",
    "            cleaned_with_label = np.insert(cleaned, 0, label)\n",
    "            df = pd.DataFrame({name : cleaned_with_label}).T\n",
    "            master_df = pd.concat([master_df, df])\n",
    "\n",
    "        if label == -1:\n",
    "            rbd_count += 1\n",
    "        else:\n",
    "            n_count += 1\n",
    "\n",
    "    print (\"Done with \" + name)\n",
    "\n",
    "print(len(master_df))\n",
    "print(rbd_count)\n",
    "print(n_count)\n",
    "master_df.to_pickle(pickle_file_path, compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
